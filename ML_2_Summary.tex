% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
]{article}
\usepackage{amsmath,amssymb}
\usepackage{lmodern}
\usepackage{ifxetex,ifluatex}
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\hypersetup{
  pdftitle={ML\_2\_Summary},
  pdfauthor={Study Crew},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}
\urlstyle{same} % disable monospaced font for URLs
\usepackage[margin=1in]{geometry}
\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{248,248,248}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.94,0.16,0.16}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.77,0.63,0.00}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\BuiltInTok}[1]{#1}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.64,0.00,0.00}{\textbf{#1}}}
\newcommand{\ExtensionTok}[1]{#1}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.00,0.00,0.81}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\ImportTok}[1]{#1}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.13,0.29,0.53}{\textbf{#1}}}
\newcommand{\NormalTok}[1]{#1}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.81,0.36,0.00}{\textbf{#1}}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textit{#1}}}
\newcommand{\RegionMarkerTok}[1]{#1}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.00,0.00,0.00}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.31,0.60,0.02}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{\textbf{\textit{#1}}}}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\setlength{\emergencystretch}{3em} % prevent overfull lines
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}
\setcounter{secnumdepth}{-\maxdimen} % remove section numbering
\ifluatex
  \usepackage{selnolig}  % disable illegal ligatures
\fi

\title{ML\_2\_Summary}
\author{Study Crew}
\date{3/9/2021}

\begin{document}
\maketitle

\hypertarget{machine-learning-2-summary-document}{%
\section{Machine Learning 2 Summary
Document}\label{machine-learning-2-summary-document}}

This document is a comprehensive summary for Machine Learning 2. It is
intended to help us study for the exams and for future reference in our
professional lives (if any companies actually use R).

\hypertarget{forward-and-backward-selection}{%
\subsection{Forward and Backward
Selection}\label{forward-and-backward-selection}}

Author: Matt Sadosuk

\hypertarget{summarydescription}{%
\subsubsection{Summary/description:}\label{summarydescription}}

\hypertarget{when-to-employ-this-methodmodel}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel}}

\hypertarget{model-code-and-inputs}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs}}

\hypertarget{model-tests}{%
\subsubsection{Model Tests:}\label{model-tests}}

\hypertarget{model-improvements}{%
\subsubsection{Model Improvements:}\label{model-improvements}}

\hypertarget{comprehensive-example}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{ridge-regression}{%
\subsection{Ridge Regression}\label{ridge-regression}}

Author: Sarah Brown

\hypertarget{summarydescription-1}{%
\subsubsection{Summary/description:}\label{summarydescription-1}}

With this method, you shrink the B coefficients of your features towards
0. It reduces variance but increases bias in the training data. It
doesn't let you make a coefficient 0 (it shrinks asymptotically) and so
no features are eliminated. So, we use this when most features are
useful and none seem irrelevant (if they did, you'd look at using lasso
perhaps). As λ goes up, beta slope goes down and the line gets flatter
which means the model is less sensative to the features. This means that
the weight decay in gradient descent is larger.

\hypertarget{when-to-employ-this-methodmodel-1}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-1}}

When the the training model is very accurate, but the test model is not,
signaling that there is a large least squares error (high variance) in
the test model. This means that the line is overfit to the training
data. You want to minimize the the cost function which is: RSS + λ *
(slope)\^{}2 {[}penalty{]} where λ is the severity of the penalty, and
is a tuning parameter. You can use ridge regression with:

Multiple regression λ(slope12 + slope22 + \ldots.) (except for
intercept)

Categorical X (binary) Slope = difference between the two categories

Logistic Regression Categorical Y Optimizes sum of likelihoods (rather
than RSS) *Multiple Regression thru Logistic Regression above, is
directly out of Professor Li's Ppt

\hypertarget{model-code-and-inputs-1}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#First, divide the data into training and testing (in this case, its 75\% training)}
\CommentTok{\# (6) Create the train (75\%) and test (25\%) data sets }
\NormalTok{train }\OtherTok{=} \FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(x), }\FunctionTok{nrow}\NormalTok{(x)}\SpecialCharTok{*}\NormalTok{.}\DecValTok{75}\NormalTok{)}
\NormalTok{test}\OtherTok{=}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{train)}
\NormalTok{y.test}\OtherTok{=}\NormalTok{y[test]}

\CommentTok{\#Create a grid of lambda valaues. Then use the glmnet() function to create a model to predict the \#training y\textquotesingle{}s using the training x\textquotesingle{}s. Use alpha = 0 for ridge regression.}
\NormalTok{grid}\OtherTok{=}\DecValTok{10}\SpecialCharTok{\^{}}\FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{, }\AttributeTok{length =}\DecValTok{120}\NormalTok{)}
\NormalTok{mod.ridge }\OtherTok{\textless{}{-}} \FunctionTok{glmnet}\NormalTok{(x[train,], y[train], }\AttributeTok{alpha=}\DecValTok{0}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{grid)}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-tests-1}{%
\subsubsection{Model Tests:}\label{model-tests-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Evaluate training model performance (how well it predicted the y{-}values) by using cross{-}validation, which is the cv.glmnet() function. (In this example code, we are creating a 12{-}fold cross{-}validation model, but by default it is a 10{-}fold cv).}
\NormalTok{cv.out.ridge }\OtherTok{\textless{}{-}} \FunctionTok{cv.glmnet}\NormalTok{(x[train,], y[train], }\AttributeTok{alpha=}\DecValTok{0}\NormalTok{, }\AttributeTok{lambda =}\NormalTok{ grid, }\AttributeTok{nfolds =} \DecValTok{12}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(cv.out.ridge)}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-improvements-1}{%
\subsubsection{Model Improvements:}\label{model-improvements-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Make predictions using the best model by using the best lambda. Create a vector of test set \#predictions.}
\NormalTok{bestlam\_r }\OtherTok{\textless{}{-}}\NormalTok{ cv.out.ridge}\SpecialCharTok{$}\NormalTok{lambda.min}
\NormalTok{ridge.pred }\OtherTok{\textless{}{-}} \FunctionTok{predict}\NormalTok{(mod.ridge, }\AttributeTok{s=}\NormalTok{bestlam\_r, }\AttributeTok{newx=}\NormalTok{x[test,])}

\CommentTok{\#Compute and display the test error rate.}
\NormalTok{MSE\_best\_ridge}\OtherTok{\textless{}{-}}\FunctionTok{mean}\NormalTok{((ridge.pred }\SpecialCharTok{{-}}\NormalTok{ y.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\hypertarget{comprehensive-example-1}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-1}}

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\#Part 1: Exploring ridge regression without using a test and train set}
\CommentTok{\#Using the hitters data set, we set up the "x" and "y" matrix values so that we can use the glmnet function. }
\NormalTok{x}\OtherTok{=}\FunctionTok{model.matrix}\NormalTok{(Salary}\SpecialCharTok{\textasciitilde{}}\NormalTok{.,HitData)[,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{]}
\NormalTok{y}\OtherTok{=}\NormalTok{HitData}\SpecialCharTok{$}\NormalTok{Salary}

\CommentTok{\#Make a grid of lambda values, and see how many coefficients you have and how many potential lambda \#values there are.}
\NormalTok{grid}\OtherTok{=}\DecValTok{10}\SpecialCharTok{\^{}}\FunctionTok{seq}\NormalTok{(}\DecValTok{10}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}\AttributeTok{length=}\DecValTok{100}\NormalTok{)}
\NormalTok{ridge.mod}\OtherTok{=}\FunctionTok{glmnet}\NormalTok{(x,y,}\AttributeTok{alpha =} \DecValTok{0}\NormalTok{,}\AttributeTok{lambda =}\NormalTok{ grid)}
\NormalTok{COEF}\OtherTok{\textless{}{-}}\FunctionTok{coef}\NormalTok{(ridge.mod)}
\FunctionTok{dim}\NormalTok{(COEF)}
\NormalTok{[}\DecValTok{1}\NormalTok{]  }\DecValTok{20} \DecValTok{100} \CommentTok{\# 20 coefficients and 100 possible lambda values}

\CommentTok{\#You can look at various lambda values and how they preform. Here is an example of looking at the \#50th lambda value from the grid. }
\NormalTok{ridge.mod}\SpecialCharTok{$}\NormalTok{lambda[}\DecValTok{50}\NormalTok{]}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\FloatTok{11497.57}
\FunctionTok{coef}\NormalTok{(ridge.mod)[,}\DecValTok{50}\NormalTok{]}
\NormalTok{  (Intercept)         AtBat          Hits         HmRun          Runs }
\FloatTok{407.356050200}   \FloatTok{0.036957182}   \FloatTok{0.138180344}   \FloatTok{0.524629976}   \FloatTok{0.230701523} 
\NormalTok{          RBI         Walks         Years        CAtBat         CHits }
  \FloatTok{0.239841459}   \FloatTok{0.289618741}   \FloatTok{1.107702929}   \FloatTok{0.003131815}   \FloatTok{0.011653637} 
\NormalTok{       CHmRun         CRuns          CRBI        CWalks       LeagueN }
  \FloatTok{0.087545670}   \FloatTok{0.023379882}   \FloatTok{0.024138320}   \FloatTok{0.025015421}   \FloatTok{0.085028114} 
\NormalTok{    DivisionW       PutOuts       Assists        Errors    NewLeagueN }
 \SpecialCharTok{{-}}\FloatTok{6.215440973}   \FloatTok{0.016482577}   \FloatTok{0.002612988}  \SpecialCharTok{{-}}\FloatTok{0.020502690}   \FloatTok{0.301433531} 
\FunctionTok{sqrt}\NormalTok{(}\FunctionTok{sum}\NormalTok{(}\FunctionTok{coef}\NormalTok{(ridge.mod)[}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,}\DecValTok{50}\NormalTok{]}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{))}\CommentTok{\# Find the L2 value}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\FloatTok{6.360612}

\CommentTok{\#Part 2: Predicting with a test and train set also using the hitters data}
\CommentTok{\#Create test and train }
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{train}\OtherTok{\textless{}{-}}\FunctionTok{sample}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\FunctionTok{nrow}\NormalTok{(x),}\FunctionTok{nrow}\NormalTok{(x)}\SpecialCharTok{/}\DecValTok{2}\NormalTok{)}
\NormalTok{test}\OtherTok{=}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{train)}
\NormalTok{y.test}\OtherTok{=}\NormalTok{y[test]}

\CommentTok{\#To choose the best lambda value, we use cv.glmnet. We can find the best lambda and associated MSE.}
\FunctionTok{set.seed}\NormalTok{(}\DecValTok{1}\NormalTok{)}
\NormalTok{cv.out}\OtherTok{=}\FunctionTok{cv.glmnet}\NormalTok{(x[train,],y[train],}\AttributeTok{alpha=}\DecValTok{0}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(cv.out)}
\NormalTok{bestlam}\OtherTok{\textless{}{-}}\NormalTok{cv.out}\SpecialCharTok{$}\NormalTok{lambda.min}
\NormalTok{bestlam }\CommentTok{\#326.0828}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\FloatTok{326.0828}
\NormalTok{ridge.pred}\OtherTok{\textless{}{-}}\FunctionTok{predict}\NormalTok{(ridge.mod,}\AttributeTok{s=}\NormalTok{bestlam,}\AttributeTok{newx =}\NormalTok{ x[test,])}
\FunctionTok{mean}\NormalTok{((ridge.pred}\SpecialCharTok{{-}}\NormalTok{y.test)}\SpecialCharTok{\^{}}\DecValTok{2}\NormalTok{) }\CommentTok{\# 139856.6}
\NormalTok{[}\DecValTok{1}\NormalTok{] }\FloatTok{139856.6}

\CommentTok{\#We can also explore what the coefficients look like using the whole data set and our best lamda \#value}
\NormalTok{out}\OtherTok{\textless{}{-}}\FunctionTok{glmnet}\NormalTok{(x,y,}\AttributeTok{alpha =} \DecValTok{0}\NormalTok{)}
\FunctionTok{predict}\NormalTok{(out,}\AttributeTok{type =} \StringTok{"coefficients"}\NormalTok{,}\AttributeTok{s=}\NormalTok{bestlam)[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{20}\NormalTok{,]}
\NormalTok{ (Intercept)        AtBat         Hits        HmRun         Runs          RBI }
 \FloatTok{15.44383135}   \FloatTok{0.07715547}   \FloatTok{0.85911581}   \FloatTok{0.60103107}   \FloatTok{1.06369007}   \FloatTok{0.87936105} 
\NormalTok{       Walks        Years       CAtBat        CHits       CHmRun        CRuns }
  \FloatTok{1.62444616}   \FloatTok{1.35254780}   \FloatTok{0.01134999}   \FloatTok{0.05746654}   \FloatTok{0.40680157}   \FloatTok{0.11456224} 
\NormalTok{        CRBI       CWalks      LeagueN    DivisionW      PutOuts      Assists }
  \FloatTok{0.12116504}   \FloatTok{0.05299202}  \FloatTok{22.09143189} \SpecialCharTok{{-}}\FloatTok{79.04032637}   \FloatTok{0.16619903}   \FloatTok{0.02941950} 
\NormalTok{      Errors   NewLeagueN }
 \SpecialCharTok{{-}}\FloatTok{1.36092945}   \FloatTok{9.12487767} 
\CommentTok{\# no coefficients are zero because in ridge regression they aren\textquotesingle{}t allowed to be}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{lasso-regression}{%
\subsection{Lasso Regression}\label{lasso-regression}}

Author: Jill Van den Dungen

\hypertarget{summarydescription-2}{%
\subsubsection{Summary/description:}\label{summarydescription-2}}

\hypertarget{when-to-employ-this-methodmodel-2}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-2}}

\hypertarget{model-code-and-inputs-2}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-2}}

\hypertarget{model-tests-2}{%
\subsubsection{Model Tests:}\label{model-tests-2}}

\hypertarget{model-improvements-2}{%
\subsubsection{Model Improvements:}\label{model-improvements-2}}

\hypertarget{comprehensive-example-2}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-2}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{principal-component-regression}{%
\subsection{Principal Component
Regression}\label{principal-component-regression}}

Author: Alex King

\hypertarget{summarydescription-3}{%
\subsubsection{Summary/description:}\label{summarydescription-3}}

\hypertarget{when-to-employ-this-methodmodel-3}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-3}}

\hypertarget{model-code-and-inputs-3}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-3}}

\hypertarget{model-tests-3}{%
\subsubsection{Model Tests:}\label{model-tests-3}}

\hypertarget{model-improvements-3}{%
\subsubsection{Model Improvements:}\label{model-improvements-3}}

\hypertarget{comprehensive-example-3}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-3}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{polynomial-regression}{%
\subsection{Polynomial Regression}\label{polynomial-regression}}

Author: Carrington Metts

\hypertarget{summarydescription-4}{%
\subsubsection{Summary/description:}\label{summarydescription-4}}

\hypertarget{when-to-employ-this-methodmodel-4}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-4}}

\hypertarget{model-code-and-inputs-4}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-4}}

\hypertarget{model-tests-4}{%
\subsubsection{Model Tests:}\label{model-tests-4}}

\hypertarget{model-improvements-4}{%
\subsubsection{Model Improvements:}\label{model-improvements-4}}

\hypertarget{comprehensive-example-4}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-4}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{step-functions}{%
\subsection{Step Functions}\label{step-functions}}

Author: Alex Russett

\hypertarget{summarydescription-5}{%
\subsubsection{Summary/description:}\label{summarydescription-5}}

\hypertarget{when-to-employ-this-methodmodel-5}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-5}}

\hypertarget{model-code-and-inputs-5}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-5}}

\hypertarget{model-tests-5}{%
\subsubsection{Model Tests:}\label{model-tests-5}}

\hypertarget{model-improvements-5}{%
\subsubsection{Model Improvements:}\label{model-improvements-5}}

\hypertarget{comprehensive-example-5}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-5}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{regression-splines}{%
\subsection{Regression Splines}\label{regression-splines}}

Author: Andrew Tremblay \& Thomas Trankle

\hypertarget{summarydescription-6}{%
\subsubsection{Summary/description:}\label{summarydescription-6}}

\textbf{Regression Splines} are more flexible than polynomials and step
functions.

This is because the are actually an extension of the two.

They involve dividing the range of \emph{X} into \emph{K} distinct
regions. Within each region, a polynomial function is fit to the data.
However, these polynomials are constrained so that they \textbf{join
smoothly at the region boundaries, or knots}. Provided that the interval
is divided into enough regions, this can produce an extremely flexible
fit.

The points where the coefficients change are called \emph{knots}.

In general, if we place \emph{K} different knots throughout the range of
\emph{X}, then we will end up fitting \emph{K + 1} different
polynomials.

\hypertarget{when-to-employ-this-methodmodel-6}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-6}}

Instead of fitting a high-degree polynomial over the entire range of
\emph{X}, \emph{piecewise polynomial regression} involves fitting
separate low-degree polynomials over different regions of \emph{X}.

We use this model when we need a high degree of flexibility.

Using more knots leads to a more flexible piecewise polynomial.

\hypertarget{model-code-and-inputs-6}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-6}}

\hypertarget{model-tests-6}{%
\subsubsection{Model Tests:}\label{model-tests-6}}

\hypertarget{model-improvements-6}{%
\subsubsection{Model Improvements:}\label{model-improvements-6}}

\hypertarget{comprehensive-example-6}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-6}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{smoothing-splines}{%
\subsection{Smoothing Splines}\label{smoothing-splines}}

Author: Emma Harrison

\hypertarget{summarydescription-7}{%
\subsubsection{Summary/description:}\label{summarydescription-7}}

A smoothing spline is a natural cubic spline with a knot at every x. Can
achieve perfect fit (RSS of 0) by going through every data point. Want a
function that makes RSS small, but keeps the line smooth. Ensure that
it's smooth by: minimizing the tuning parameter.

\hypertarget{when-to-employ-this-methodmodel-7}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-7}}

One of the 4 non-linear model options. lots of flexibility lots of
degrees of freedom (one @ each knot = sample size n)

\hypertarget{model-code-and-inputs-7}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-7}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{9}\NormalTok{) Now let}\StringTok{\textquotesingle{}s fit smoothing splines with cross{-}validation}
\StringTok{regression\_fit=smooth.spline(x,y,df=12)   \#use the first fit to set df}
\StringTok{smooth\_fit=smooth.spline(x,y, cv=TRUE)  \#fits the training data with LOOCV}
\StringTok{df= Degrees of freedom}
\StringTok{cv= cross validation}
\StringTok{(10) Display number of degrees of freedom in the cross{-}validated smoothing spline.}
\StringTok{smooth\_fit$df   \#df produces splines at uniform knots}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-tests-7}{%
\subsubsection{Model Tests:}\label{model-tests-7}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{(}\DecValTok{11}\NormalTok{) Use the best model to predict y}\SpecialCharTok{{-}}\NormalTok{values }\ControlFlowTok{for}\NormalTok{ the }\DecValTok{50}\NormalTok{ new x}\StringTok{\textquotesingle{}s from step (7) above}
\StringTok{ylims=range(y)}
\StringTok{vector1\textless{}{-}seq(from=ylims[1],to=ylims[2], length.out = 50)}
\StringTok{Visually inspect the plot of predicted values against X values}
\StringTok{(12)    Plot the full sample\textquotesingle{}}\NormalTok{s x}\StringTok{\textquotesingle{}s and y\textquotesingle{}}\NormalTok{s.}
\NormalTok{xlims}\OtherTok{=}\FunctionTok{range}\NormalTok{(x)}
\FunctionTok{plot}\NormalTok{(x,y,}\AttributeTok{xlim=}\NormalTok{xlims, }\AttributeTok{ylim=}\NormalTok{ylims,}\AttributeTok{cex=}\NormalTok{.}\DecValTok{5}\NormalTok{,}\AttributeTok{col=}\StringTok{"darkgrey"}\NormalTok{)}
\FunctionTok{title}\NormalTok{(}\StringTok{"Smoothing Spline"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{model-improvements-7}{%
\subsubsection{Model Improvements:}\label{model-improvements-7}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{N}\SpecialCharTok{/}\NormalTok{A... would just use a different model}
\end{Highlighting}
\end{Shaded}

\hypertarget{comprehensive-example-7}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-7}}

\begin{Shaded}
\begin{Highlighting}[]
\SpecialCharTok{\textgreater{}} \FunctionTok{library}\NormalTok{(splines)}
\SpecialCharTok{\textgreater{}}\NormalTok{ fit}\OtherTok{=}\FunctionTok{lm}\NormalTok{(wage∼}\FunctionTok{bs}\NormalTok{(age ,}\AttributeTok{knots=}\FunctionTok{c}\NormalTok{(}\DecValTok{25}\NormalTok{,}\DecValTok{40}\NormalTok{,}\DecValTok{60}\NormalTok{) ),}\AttributeTok{data=}\NormalTok{Wage)}
\SpecialCharTok{\textgreater{}}\NormalTok{ pred}\OtherTok{=}\FunctionTok{predict}\NormalTok{ (fit ,}\AttributeTok{newdata =}\FunctionTok{list}\NormalTok{(}\AttributeTok{age=}\NormalTok{age.grid),}\AttributeTok{se=}\NormalTok{T)}
\SpecialCharTok{\textgreater{}} \FunctionTok{plot}\NormalTok{(age ,wage ,}\AttributeTok{col=}\StringTok{"gray"}\NormalTok{)}
\SpecialCharTok{\textgreater{}} \FunctionTok{lines}\NormalTok{(age.grid ,pred}\SpecialCharTok{$}\NormalTok{fit ,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\SpecialCharTok{\textgreater{}} \FunctionTok{lines}\NormalTok{(age.grid ,pred}\SpecialCharTok{$}\NormalTok{fit }\SpecialCharTok{+}\DecValTok{2}\SpecialCharTok{*}\NormalTok{pred}\SpecialCharTok{$}\NormalTok{se ,}\AttributeTok{lty=}\StringTok{"dashed "}\NormalTok{)}
\SpecialCharTok{\textgreater{}} \FunctionTok{lines}\NormalTok{(age.grid ,pred}\SpecialCharTok{$}\NormalTok{fit }\SpecialCharTok{{-}}\DecValTok{2}\SpecialCharTok{*}\NormalTok{pred}\SpecialCharTok{$}\NormalTok{se ,}\AttributeTok{lty=}\StringTok{"dashed "}\NormalTok{)}
\SpecialCharTok{\textgreater{}}\NormalTok{ fit2}\OtherTok{=}\FunctionTok{lm}\NormalTok{(wage∼}\FunctionTok{ns}\NormalTok{(age ,}\AttributeTok{df=}\DecValTok{4}\NormalTok{),}\AttributeTok{data=}\NormalTok{Wage) }
\SpecialCharTok{\textgreater{}}\NormalTok{ pred2}\OtherTok{=}\FunctionTok{predict}\NormalTok{ (fit2 ,}\AttributeTok{newdata=}\FunctionTok{list}\NormalTok{(}\AttributeTok{age=}\NormalTok{age.grid),}\AttributeTok{se=}\NormalTok{T)}
\SpecialCharTok{\textgreater{}} \FunctionTok{lines}\NormalTok{(age.grid , pred2}\SpecialCharTok{$}\NormalTok{fit ,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{)}
\SpecialCharTok{\textgreater{}} \FunctionTok{plot}\NormalTok{(age ,wage ,}\AttributeTok{xlim=}\NormalTok{agelims ,}\AttributeTok{cex =}\NormalTok{.}\DecValTok{5}\NormalTok{,}\AttributeTok{col=}\StringTok{" darkgrey "}\NormalTok{) }
\SpecialCharTok{\textgreater{}} \FunctionTok{title}\NormalTok{(}\StringTok{"Smoothing Spline "}\NormalTok{) }\SpecialCharTok{\textgreater{}}\NormalTok{ fit}\OtherTok{=}\NormalTok{smooth }\FunctionTok{.spline}\NormalTok{(age ,wage ,}\AttributeTok{df=}\DecValTok{16}\NormalTok{) }
\SpecialCharTok{\textgreater{}}\NormalTok{ fit2}\OtherTok{=}\FunctionTok{smooth.spline}\NormalTok{ (age ,wage ,}\AttributeTok{cv=}\ConstantTok{TRUE}\NormalTok{) }
\SpecialCharTok{\textgreater{}}\NormalTok{ fit2}\SpecialCharTok{$}\NormalTok{df}
\SpecialCharTok{\textgreater{}} \FunctionTok{lines}\NormalTok{(fit ,}\AttributeTok{col=}\StringTok{"red"}\NormalTok{,}\AttributeTok{lwd =}\DecValTok{2}\NormalTok{)}
\SpecialCharTok{\textgreater{}} \FunctionTok{lines}\NormalTok{(fit2 ,}\AttributeTok{col=}\StringTok{"blue"}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{) }
\SpecialCharTok{\textgreater{}} \FunctionTok{legend}\NormalTok{ (}\StringTok{"topright "}\NormalTok{,}\AttributeTok{legend=}\FunctionTok{c}\NormalTok{(}\StringTok{"16 DF"}\NormalTok{ ,}\StringTok{"6.8 DF"}\NormalTok{), }\AttributeTok{col=}\FunctionTok{c}\NormalTok{(}\StringTok{"red"}\NormalTok{,}\StringTok{"blue"}\NormalTok{),}\AttributeTok{lty=}\DecValTok{1}\NormalTok{,}\AttributeTok{lwd=}\DecValTok{2}\NormalTok{, }\AttributeTok{cex =}\NormalTok{.}\DecValTok{8}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{local-regression}{%
\subsection{Local Regression}\label{local-regression}}

Author: Kayleigh Gillis

\hypertarget{summarydescription-8}{%
\subsubsection{Summary/description:}\label{summarydescription-8}}

\hypertarget{when-to-employ-this-methodmodel-8}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-8}}

\hypertarget{model-code-and-inputs-8}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-8}}

\hypertarget{model-tests-8}{%
\subsubsection{Model Tests:}\label{model-tests-8}}

\hypertarget{model-improvements-8}{%
\subsubsection{Model Improvements:}\label{model-improvements-8}}

\hypertarget{comprehensive-example-8}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-8}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{gam}{%
\subsection{GAM}\label{gam}}

Author: Akram Bijapuri

\hypertarget{summarydescription-9}{%
\subsubsection{Summary/description:}\label{summarydescription-9}}

\hypertarget{when-to-employ-this-methodmodel-9}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-9}}

\hypertarget{model-code-and-inputs-9}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-9}}

\hypertarget{model-tests-9}{%
\subsubsection{Model Tests:}\label{model-tests-9}}

\hypertarget{model-improvements-9}{%
\subsubsection{Model Improvements:}\label{model-improvements-9}}

\hypertarget{comprehensive-example-9}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-9}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{tree-classification-and-regression}{%
\subsection{Tree Classification and
Regression}\label{tree-classification-and-regression}}

Author: Ian Lawson

\hypertarget{summarydescription-10}{%
\subsubsection{Summary/description:}\label{summarydescription-10}}

\hypertarget{when-to-employ-this-methodmodel-10}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-10}}

\hypertarget{model-code-and-inputs-10}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-10}}

\hypertarget{model-tests-10}{%
\subsubsection{Model Tests:}\label{model-tests-10}}

\hypertarget{model-improvements-10}{%
\subsubsection{Model Improvements:}\label{model-improvements-10}}

\hypertarget{comprehensive-example-10}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-10}}

\begin{center}\rule{0.5\linewidth}{0.5pt}\end{center}

\hypertarget{bagging-and-random-forest}{%
\subsection{Bagging and Random Forest}\label{bagging-and-random-forest}}

Author: Witty Wittyngham

\hypertarget{summarydescription-11}{%
\subsubsection{Summary/description:}\label{summarydescription-11}}

\hypertarget{when-to-employ-this-methodmodel-11}{%
\subsubsection{When to employ this
method/model:}\label{when-to-employ-this-methodmodel-11}}

\hypertarget{model-code-and-inputs-11}{%
\subsubsection{Model Code and Inputs:}\label{model-code-and-inputs-11}}

\hypertarget{model-tests-11}{%
\subsubsection{Model Tests:}\label{model-tests-11}}

\hypertarget{model-improvements-11}{%
\subsubsection{Model Improvements:}\label{model-improvements-11}}

\hypertarget{comprehensive-example-11}{%
\subsubsection{Comprehensive Example:}\label{comprehensive-example-11}}

\end{document}
